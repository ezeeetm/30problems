# 30problems

VERY good sources!:
* https://www.analyticsvidhya.com/blog/2018/05/24-ultimate-data-science-projects-to-boost-your-knowledge-and-skills/
* https://www.kaggle.com/m2skills/datasets-and-tutorial-kernels-for-beginners
* https://www.kaggle.com/ezeeetm/titanic-hello-world-random-forest/edit (<solves titanic several different ways)
* https://github.com/python-engineer/MLfromscratch
* https://www.dataquest.io/blog/top-10-machine-learning-algorithms-for-beginners/
* https://explained.ai/
* https://mlbook.explained.ai/

**Some cool problems
https://mlcourse.ai/assignments
https://www.kaggle.com/m2skills/datasets-and-tutorial-kernels-for-beginners

**Original Reddit Thread:**
* https://www.reddit.com/r/datascience/comments/838tlf/there_are_way_too_many_getting_started_with_data/

**Reddit thread to crowdthink 'the fundamental 10' problems (largely a failure, but some good feedback, and at least one potential project contributor candidate to recruit)**
* https://www.reddit.com/r/datascience/comments/84xcbl/what_is_your_personal_list_of_the_10_most/

**Must skim these to understand the fundamental thought process/methodology being suggested:**
* A Mathematician's Lament: https://www.maa.org/external_archive/devlin/LockhartsLament.pdf (replace 'math' with 'data science' or 'machine learning' in that document)
* Making Learning Whole, by David Perkins: https://www.gse.harvard.edu/news/uk/09/01/education-bat-seven-principles-educators (especially 'playing the whole game')
* https://youtu.be/kzt3-FHdAeM?t=2m17s

**resources we can borrow ideas from**
* https://www.kaggle.com/learn/overview
* https://philippmuens.com/gradient-descent-from-scratch/
* https://victorzhou.com/blog/intro-to-neural-networks/
* https://theappsolutions.com/blog/development/machine-learning-algorithm-types/
* https://techcrunch.com/2018/04/05/cometml-wants-to-do-for-machine-learning-what-github-did-for-code/
* https://www.reddit.com/r/learnmachinelearning/comments/89fndb/machine_learning_is_hard_how_do_you_guys_do_it/
* https://academy.microsoft.com/en-us/professional-program/tracks/artificial-intelligence/
* http://www-bcf.usc.edu/~gareth/ISL/
* https://www.manning.com/books/deep-learning-with-python
* https://www.udemy.com/datascience/
* https://www.udemy.com/deeplearning
* https://www.youtube.com/channel/UC33qFpcu7eHFtpZ6dp3FFXw/videos
* http://course.fast.ai/
* http://course.fast.ai/part2.html
* https://cloud.google.com/training/data-ml
* https://ai.google/education/#?modal_active=none
* https://www.kaggle.com/learn/overview
* https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/
* https://medium.com/deep-math-machine-learning-ai/different-types-of-machine-learning-and-their-types-34760b9128a2
* https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861
* https://elitedatascience.com/machine-learning-projects-for-beginners
* https://www.kaggle.com/annavictoria/ml-friendly-public-datasets <<<<very good
* https://www.kaggle.com/rtatman/fun-beginner-friendly-datasets?scriptVersionId=1648117


* http://resources.wolframcloud.com/NeuralNetRepository (click on 'browse by task type | input domain')
* https://docs.google.com/document/d/11VAATynYgdbD3eOPSiIDV1DKOz_bt2gypTcl097fBJU/edit (Alex R. Document)


**some aligned thoughts from the community**
* https://www.reddit.com/r/MachineLearning/comments/7i1uer/n_yann_lecun_response_to_ali_rahimis_nips_lecture/
>  Yann, thanks for the thoughtful reaction. "If you don't like what's happening, fix it" is exactly what Moritz Hardt told me a year ago. It's been hard to make progress with just a small group, and to be honest, I'm overwhelmed by the scale of the task. The talk was a plea for others to help.

> I don't think the problem is one of theory. **Math for math's sake won't help. The problem is one of pedagogy. I'm asking for simple experiments and simple theorems so we can all communicate the insights without confusion. You've probably gotten so good at building deep models because you've run more experiments than almost any of us. Imagine the confusion of a newcomer to the field. What we do looks like magic because we don't talk in terms of small building blocks. We talk about entire models working as a whole. It's a mystifying onboarding process.**

> And I agree that alchemical approaches are important. They speed us up. They fix immediate problems. I have the deepest respect for people who quickly build intuitions in their head and build systems that work. You, and many of my colleagues at Google have this impressive skill. You're a rare breed. Part of my call to rigor is for those who're good at this alchemical way of thinking to **provide pedagogical nuggets to the rest of us so we can approach your level of productivity. The "rigor" i'm asking for are the pedagogical nuggets: simple experiments, simple theorems.**

![ML MAP](https://github.com/ezeeetm/30problems/blob/master/img/ml%20map.PNG)
